{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BtBLu3ZB6C-8"
   },
   "source": [
    "# 1. Dataset and Features\n",
    "\n",
    "We are using the Spotify dataset. In this project, we wish to explore the relationship between the various numerical columns in the Spotify dataset to create predictions about a track given its characteristics. Specifically, we're interested in the correlations between numerical columns such as valence, energy, danceability, speechiness, and instrumentalness. Understanding these correlations will allow us to predict statistics such as popularity based on other track information.  \n",
    "\n",
    "We start by importing the dataset (shown below), using the `pandas` link from HuggingFace.\n",
    "Note for project members: you have to run this every time you reopen the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NWh2XcXv51Sz"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tqdm as notebook_tqdm\n",
    "spotify = pd.read_csv(\"hf://datasets/maharshipandya/spotify-tracks-dataset/dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XlezAgze767k"
   },
   "outputs": [],
   "source": [
    "# import some libraries\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.options.mode.copy_on_write = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xpiemk2I7ItJ"
   },
   "source": [
    "# 2. Getting started\n",
    "\n",
    "Print out the columns of the dataset.\n",
    "Print out the first 20 rows of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kqnfrmFx7HVI",
    "outputId": "19bc2a5e-77e5-4a31-db63-a388782906aa"
   },
   "outputs": [],
   "source": [
    "spotify.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spotify.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "zikedWp78POW",
    "outputId": "5d324cf9-950a-41b3-9098-ba0b252c40bc"
   },
   "outputs": [],
   "source": [
    "# Get 20 random rows\n",
    "spotify.sample(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Z6PyDHus8Tud",
    "outputId": "d702322f-7713-422a-fa15-0b54ea8e3ec1"
   },
   "outputs": [],
   "source": [
    "# Check the shape of spotify dataset\n",
    "spotify.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U4R5CVJT8VLT",
    "outputId": "2d9959b3-5fba-4f55-8213-c12224fe6c9e"
   },
   "outputs": [],
   "source": [
    "# Sanity check: get the counts of each artist and track_name combination\n",
    "counts = spotify.groupby(['artists', 'track_name']).size().reset_index(name='count')\n",
    "print(counts)\n",
    "print(\"There are \" + str(sum(counts['count'] != 1)) + \" artist, track_name combinations that are non-unique.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ab7Nmx2JaWnl"
   },
   "source": [
    "### Sanity checks!\n",
    "\n",
    "- Are there any entries with null values\n",
    "- Do numbers fall in the expected range\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uPj9e86ZsE4C",
    "outputId": "e42e700f-7d78-46b2-ef67-f7ff3daffbd7"
   },
   "outputs": [],
   "source": [
    "# popularity between 0 and 100\n",
    "sum(spotify['popularity'] < 0) + sum(spotify['popularity'] > 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AAxU2scuaenq",
    "outputId": "e9cc9856-c863-4f6a-8206-2e313a1659d1"
   },
   "outputs": [],
   "source": [
    "# danceability between 0.0 and 1.0\n",
    "sum(spotify['danceability'] < 0.0) + sum(spotify['danceability'] > 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZpPM45ZAcYyZ",
    "outputId": "5fef807c-9e87-4660-c39d-e2ead3dd4a50"
   },
   "outputs": [],
   "source": [
    "# energy is between 0.0 to 1.0\n",
    "sum(spotify['energy'] < 0.0) + sum(spotify['energy'] > 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BOr4Ow9mbHmF",
    "outputId": "a5c51b8d-ed02-49d8-cd0e-3af2701f92fd"
   },
   "outputs": [],
   "source": [
    "# mode is 0 or 1\n",
    "sum(x not in [0,1] for x in spotify['mode'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i7ND7P5NcflU",
    "outputId": "faee2c2d-f58e-41ba-e78d-a7c5471e7702"
   },
   "outputs": [],
   "source": [
    "# speechiness between 0.0 and 1.0\n",
    "sum(spotify['speechiness'] < 0.0) + sum(spotify['speechiness'] > 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gEVJB-tYc-4e",
    "outputId": "620e9a3b-9814-489f-b76d-78bd084e6664"
   },
   "outputs": [],
   "source": [
    "# acousticness between 0.0 and 1.0\n",
    "sum(spotify['acousticness'] < 0.0) + sum(spotify['acousticness'] > 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2pHzb8YrdCeo",
    "outputId": "9862daa9-774c-4315-890a-1657ff7a3dd8"
   },
   "outputs": [],
   "source": [
    "# instrumentalness between 0.0 and 1.0\n",
    "sum(spotify['instrumentalness'] < 0.0) + sum(spotify['instrumentalness'] > 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Cud3XpMzdPi5",
    "outputId": "6ae84ec7-1f76-48e4-f949-4c4db7d6c98e"
   },
   "outputs": [],
   "source": [
    "# liveness between 0.0 and 1.0\n",
    "sum(spotify['liveness'] < 0.0) + sum(spotify['liveness'] > 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wAwXLsPYdTr9",
    "outputId": "be2e3b3b-0e09-4685-ab00-52d62827910b"
   },
   "outputs": [],
   "source": [
    "# valence between 0.0 and 1.0\n",
    "sum(spotify['valence'] < 0.0) + sum(spotify['valence'] > 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_JZNDcJjew2L",
    "outputId": "6d3792e3-8924-4f44-e9bd-1814fc92f5b9"
   },
   "outputs": [],
   "source": [
    "# positive tempo\n",
    "sum(spotify['tempo'] < 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PWVKyIf6dYsO",
    "outputId": "6d6ed6a8-80b8-4df6-f3e8-73f250101b34"
   },
   "outputs": [],
   "source": [
    "# time signature between 3 and 7 (inclusive)\n",
    "sum(spotify['time_signature'] < 3) + sum(spotify['time_signature'] > 7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GcxW47lKnw2A"
   },
   "source": [
    "### Let's visualize some missing values!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "id": "MUnpdgTRnzgi",
    "outputId": "388aa499-0222-443b-cc75-936098e6c2ed"
   },
   "outputs": [],
   "source": [
    "# identify whether each tempo value is zero\n",
    "# and group by genre (index)\n",
    "# count number of zero values\n",
    "zero_tempo_by_genre = spotify.set_index(\"track_genre\")[\"tempo\"].eq(0).groupby(level=0).sum()\n",
    "\n",
    "# Convert the result to a DataFrame \n",
    "zero_tempo_by_genre_df = zero_tempo_by_genre.reset_index()\n",
    "\n",
    "# Create a bar chart \n",
    "px.bar(zero_tempo_by_genre_df,\n",
    "       x='track_genre',\n",
    "       y='tempo',  # The count of zero tempo values\n",
    "       labels={'0': 'Number of zero tempo values', 'genre': 'Genre'},\n",
    "       title=\"Zero Tempo Values by Genre\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify whether each valence value is zero\n",
    "# and group by genre (index)\n",
    "# count number of zero values\n",
    "zero_valence_by_genre = spotify.set_index(\"track_genre\")[\"valence\"].eq(0).groupby(level=0).sum()\n",
    "\n",
    "# Convert the result to a DataFrame \n",
    "zero_valence_by_genre_df = zero_valence_by_genre.reset_index()\n",
    "\n",
    "# Create a bar chart \n",
    "px.bar(zero_valence_by_genre_df,\n",
    "       x='track_genre',\n",
    "       y='valence',  # The count of zero valence values\n",
    "       labels={'0': 'Number of zero valence values', 'genre': 'Genre'},\n",
    "       title=\"Zero Valence Values by Genre\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter time_signatures for values that are either less than 3 or greater than 7\n",
    "invalid_time_signatures = spotify.set_index(\"track_genre\")[\"time_signature\"] \\\n",
    "    .apply(lambda x: x < 3 or x > 7)  # Create a boolean series where True indicates invalid values\n",
    "\n",
    "# Group by track_genre and sum the invalid counts\n",
    "time_signatures = invalid_time_signatures.groupby(level=0).sum()\n",
    "\n",
    "time_signatures_df = time_signatures.reset_index()\n",
    "\n",
    "# Create a bar chart \n",
    "px.bar(time_signatures_df,\n",
    "       x = 'track_genre',\n",
    "       y='time_signature',  # The count of invalid time signature values\n",
    "       labels={'0': 'Number of invalid time signatures', 'genre': 'Genre'},\n",
    "       title=\"Invalid Time Signature by Genre\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examining relationships between single variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Danceability and Energy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Danceability describes how easy it is to dance to a song, while energy measures how intense and active a track is. One would expect these to have a positive correlation, which the graph shows to a small extent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "danceability = spotify['danceability']\n",
    "energy = spotify['energy']\n",
    "plt.scatter(danceability, energy, s=0.1)\n",
    "plt.xlabel('Danceability')\n",
    "plt.ylabel('Energy')\n",
    "plt.title('Energy and Danceability of Spotify Tracks')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Valence and Danceability\n",
    "\n",
    "Valence is a measure describing how \"positive\" a track is, while danceability describes how suitable a track is to dance to. One might expect the two to have a positive correlation since more upbeat songs are often faster and more rhythmic, and thus easier to dance to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "danceability = spotify['danceability']\n",
    "energy = spotify['valence']\n",
    "plt.scatter(danceability, energy, s=0.1)\n",
    "plt.xlabel('Danceability')\n",
    "plt.ylabel('Valence')\n",
    "plt.title('Valence and Danceability of Spotify Tracks')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Speechiness and Instrumentalness\n",
    "\n",
    "Speechiness measures the presence of spoken words in a song, while instrumentalness predicts if a song contains no vocals. These two should be inversely related, which this graph somewhat shows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speechiness = spotify['speechiness']\n",
    "instrumentalness = spotify['instrumentalness']\n",
    "plt.scatter(speechiness, instrumentalness, s=0.1)\n",
    "plt.xlabel('Speechiness')\n",
    "plt.ylabel('Instrumentalness')\n",
    "plt.title('Speechiness and Instrumentalness of Spotify Tracks')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Popularity with Respect to Valence and Danceability\n",
    "\n",
    "Popularity measures how popular a song is. Valence and danceability are both numerical measures of how \"positive\" a track is, and how suitable it is to dance to, respectively. \n",
    "\n",
    "The heatmap below will show the correlation between valence, danceability, and tracks with low popularity (defined as popularity below 10). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "# Filter the DataFrame for tracks where 'popularity' < 10\n",
    "spotify_filtered = spotify[spotify['popularity'] < 10]\n",
    "\n",
    "# Put 'valence' and 'danceability' into bins\n",
    "spotify_filtered['valence_bin'] = pd.cut(spotify_filtered['valence'], bins=10)\n",
    "spotify_filtered['danceability_bin'] = pd.cut(spotify_filtered['danceability'], bins=10)\n",
    "\n",
    "# Create a table where rows are binned 'valence' and columns are binned 'danceability', and values are the counts\n",
    "heatmap_data = spotify_filtered.pivot_table(index='valence_bin', columns='danceability_bin', aggfunc='size', fill_value=0)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Create the heatmap with seaborn\n",
    "sns.heatmap(heatmap_data, cmap='coolwarm', annot=True, fmt='d')\n",
    "\n",
    "# Add labels and title\n",
    "plt.title('Heatmap of Valence vs Danceability (Popularity < 10)', fontsize=16)\n",
    "plt.xlabel('Danceability Bins', fontsize=12)\n",
    "plt.ylabel('Valence Bins', fontsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Feature Imputation\n",
    "The Spotify dataset contains many missing values, which are largely encoded as placeholders, although `null` values are also used. Such values are incompatible with our models as they create nonsensical patterns in the data. \n",
    "\n",
    "A basic strategy (shown below) would be to discard entire rows or columns which contain the missing or placeholder values. However, the data lost may be valuable, and it may be a better strategy to **impute** values by inferring them from known data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are some features which we have identified as missing or placeholder values: \n",
    "\n",
    "- Remove duplicate rows (same artist, same song, different genre or album)\n",
    "  - These will have different track IDs\n",
    "- Replace missing values\n",
    "- Remove \"Unnamed: 0\" column (which is just the row number)\n",
    "\n",
    "- Missing value:\n",
    "  - Explicit = unknown\n",
    "  - Key = -1\n",
    "\n",
    "- Time signatures < 3 and > 7\n",
    "  - Time signature of 0, usually means \"sleep\" genre"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note for project members\n",
    "**Warning**: `inPlace = True` will modify the original DataFrame. For example, if you `drop_duplicates inPlace`, the original spotify DataFrame will now never contain duplicates.\n",
    "\n",
    "`drop_duplicates` has a `subset` argument. It will consider two rows duplicates if they have the same values for `subset`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicate rows (the same song by same artist under different genre or album)\n",
    "spotify_new = spotify.drop_duplicates(subset=['artists', 'track_name'], keep='first')\n",
    "spotify_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping the Unnamed column (which is just the row index)\n",
    "spotify = spotify.drop(columns=['Unnamed: 0'])\n",
    "spotify"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `impute_feature()` function\n",
    "\n",
    "To handle any potential missing values or placeholders in the data. \n",
    "\n",
    "Because the Spotify dataset has many \"placeholder\" values rather than NaN or real missing data, we found it helpful to specify a `placeholder_value` which will be treated as a NaN value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_feature(data, feature, group, impute_method=\"average\", placeholder_value = 0):\n",
    "  '''\n",
    "  Imputes missing or placeholder values in a specified feature column based on the given impute method.\n",
    "  \n",
    "  Parameters:\n",
    "  - data (pandas.DataFrame): The DataFrame containing the data to impute.\n",
    "  - feature (str): The name of the column where missing or placeholder values should be imputed.\n",
    "  - group (str or list of str): Column(s) by which to group the data before applying the imputation.\n",
    "  - impute_method (str, optional): The method used to impute the missing values. Defaults to \"average\". Currently, \n",
    "    only \"average\" is supported. This method performs forward and backward fills, then takes the average of both.\n",
    "  - placeholder_value (numeric, optional): The placeholder value (like 0) that should be treated as missing, used\n",
    "    when impute_method is \"placeholder\". Defaults to 0.\n",
    "\n",
    "  Returns:\n",
    "  - pandas.Series: A Series with the imputed values for the specified feature.\n",
    "\n",
    "  Raises:\n",
    "  - ValueError: If an unsupported impute method is provided.\n",
    "  '''\n",
    "  if(impute_method == \"placeholder\"):\n",
    "          # Replace placeholder values with NaN\n",
    "          data[feature] = data[feature].replace(placeholder_value, np.nan)\n",
    "\n",
    "  if impute_method in [\"average\", \"placeholder\"]:\n",
    "      # Change the impute method argument to lowercase\n",
    "      impute_method = impute_method.lower()\n",
    "      # Create 2 temp variables equal to feature\n",
    "      data = data.assign(imputed_feature_prev=data[feature], imputed_feature_next=data[feature])\n",
    "      # Fill first var with forward fill\n",
    "      data[\"imputed_feature_prev\"] = data.groupby(group)[\"imputed_feature_prev\"].ffill()\n",
    "      # Fill second var with backward fill\n",
    "      data[\"imputed_feature_next\"] = data.groupby(group)[\"imputed_feature_next\"].bfill()\n",
    "      # Define feature_imputed column to be mean of the forward and backward fill\n",
    "      data[\"feature_imputed\"] = data[[\"imputed_feature_next\", \"imputed_feature_prev\"]].mean(axis=1, skipna=True)\n",
    "      # Impute remaining missing values with 0\n",
    "      data[\"feature_imputed\"] = data[\"feature_imputed\"].fillna(0)\n",
    "      # Remove two temp vars\n",
    "      data = data.drop(columns=[\"imputed_feature_prev\", \"imputed_feature_next\"])\n",
    "      return data[\"feature_imputed\"]\n",
    "  else:\n",
    "      raise ValueError(\"Invalid impute_method\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test impute_feature and placeholder_value argument\n",
    "spotify[\"imputed_valence\"] = impute_feature(spotify, \n",
    "                                            feature = \"valence\", \n",
    "                                            group = \"track_genre\",\n",
    "                                            impute_method = \"placeholder\", \n",
    "                                            placeholder_value = 0.6190)\n",
    "\n",
    "spotify[[\"track_name\", \"popularity\", \"danceability\", \"energy\", \"valence\", \"imputed_valence\"]].sample(20, random_state=1259)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
